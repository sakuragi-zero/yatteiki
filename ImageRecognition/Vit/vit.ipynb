{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1ru/hqtBhe+PNbzQHWCvR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakuragi-zero/yatteiki/blob/master/ImageRecognition/Vit/vit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crHVbR10N6AX"
      },
      "outputs": [],
      "source": [
        "!rm -r sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-qでインデックスを表示しない"
      ],
      "metadata": {
        "id": "AunCajduV_4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u-bMNBraAS1",
        "outputId": "07bcc01b-5241-4bb9-a791-920c8dd4a02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 25.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "import operator\n",
        "\n",
        "from PIL import Image\n",
        "from timm.optim import create_optimizer\n",
        "from timm.utils import AverageMeter, accuracy\n",
        "from timm.utils.summary import update_summary\n",
        "from timm.data import create_dataset, create_loader,resolve_data_config\n",
        "from torch.autograd import Variable\n",
        "from IPython.display import display\n",
        "\n"
      ],
      "metadata": {
        "id": "FY5iBbi0WRpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='Training Config', add_help=False)\n",
        "parser.add_argument('--opt',\n",
        "                    default='sgd',\n",
        "                    type=str,\n",
        "                    metavar='OPTIMIZER',\n",
        "                    help='Optimizer (default: \"sgd\")')\n",
        "\n",
        "parser.add_argument('--weight_decay',\n",
        "                    type=float,\n",
        "                    default=0.0001,\n",
        "                    help='weight decay (default: 0.0001)')\n",
        "\n",
        "parser.add_argument('--lr',\n",
        "                    type=float,\n",
        "                    default=0.01,\n",
        "                    metavar='LR',\n",
        "                    help='learning rate (default: 0.01)')\n",
        "\n",
        "paraer.add_argument('--momentum',\n",
        "                    type=float,\n",
        "                    default=0.9,\n",
        "                    metavar='M',\n",
        "                    help='Optimizer momentum (dafault:0.9)')\n",
        "\n",
        "parser.add_argument('--input-size',\n",
        "                    default=None,\n",
        "                    nargs=3,\n",
        "                    type=int,\n",
        "                    metavar='N N N',\n",
        "                    help='Input all image dimensions (d h w, e.g. --input-size 3 224 224), uses model default if empty')\n",
        "\n",
        "args = parser.parse_args(['--input-size', '3', '224', '224'])"
      ],
      "metadata": {
        "id": "3uP15dDUZLOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n"
      ],
      "metadata": {
        "id": "z-mZz8I7gpqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#データパスの指定\n",
        "dataset_path = '/content/drive/MyDrive/VisionTransformer/'"
      ],
      "metadata": {
        "id": "e9sSeNC3g--r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#対応モデルの確認\n",
        "model_names = timm.list_models(pretrained=True)\n",
        "model_names"
      ],
      "metadata": {
        "id": "GMk2cllYhfUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#{'clear' : 0, 'cloudy' : 1}の2種類\n",
        "#データの中のクラス数を指定する\n",
        "NUM_FINETUNE_CLASSES = 2\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)\n",
        "#GPUを使用\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "EjLwXzAaiX3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_config = resolve_data_config(vars(args), model=model)"
      ],
      "metadata": {
        "id": "jRbv_kaglZLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの作成"
      ],
      "metadata": {
        "id": "G3T1eo9ammdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = create_dataset('train', root=os.path.join(dataset_path, 'train'), is_training=True, batch_size=BATCH_SIZE)\n",
        "dataset_eval = create_dataset('validation', root=os.path.join(dataset_path, 'validation'), is_training=False, batch_size=BATCH_SIZE)\n",
        "dataset_test = create_dataset('test', root=os.path.join(dataset_path, 'test'), is_training=False, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "yTpUl9u0l4DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train = create_loader(dateset_train, input_size=data_config['input_size'],batch_size=BATCH_SIZE, is_training=True, num_workers=NUM_FINETUNE_CLASSES)\n",
        "loader_eval = create_loader(dateset_eval, input_size=data_config['input_size'],batch_size=BATCH_SIZE, is_training=False, num_workers=NUM_FINETUNE_CLASSES)\n",
        "loader_test = create_loder(dataset_test, input_size=data_config['input_size'],batch_size=BATCH_SIZE, is_training=False, num_workers=NUM_FINETUNE_CLASSES)"
      ],
      "metadata": {
        "id": "dSUoZlAQoqBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPUに乗せます\n",
        "train_loss_fn = nn.crossEntropyLoss().cuda()\n",
        "validate_lossfn = nn.CrossEntropyLoss().cuda()"
      ],
      "metadata": {
        "id": "cJ7XImcNxftu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = create_optimizer(args, model)"
      ],
      "metadata": {
        "id": "itCUOPyjyEa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch, model, loader, optimizer, loss_fn, args, output_dir=None):\n",
        "  second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "  batch_time_m = AverageMeter()\n",
        "  data_time_m = AverageMeter()\n",
        "  losses_m = AverageMeter()\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  end = time.time()\n",
        "  num_updates = epoch * len(loader)\n",
        "  for _, (input, target) in enumerate(loader):\n",
        "    data_time_m.update(time.time() - end)\n",
        "\n",
        "    output = model(input)\n",
        "    loss = loss_fn(output, target)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward(create_graph=second_order)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    num_updates += 1\n",
        "    batch_time_m.update(time.time() - end)\n",
        "\n",
        "    end = time.time()\n",
        "  if hasattr(optimizer, 'sync_lookahead'):\n",
        "    optimizer.sync_lookahead()\n",
        "  \n",
        "  return OrderedDict([('loss', losses_m.avg)])\n",
        "  "
      ],
      "metadata": {
        "id": "8v5Mp2PPygfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, loader, loss_fn, args):\n",
        "  batch_tume_m = AverageMeter()\n",
        "  losses_m = AverageMeter()\n",
        "  accuracy_m = AverageMeter()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  end = time.time()\n",
        "  with torch.no_grad():\n",
        "    for _, (input, target) in enumerate(loader):\n",
        "      input = input.cuda()\n",
        "      target = target.cuda()\n",
        "\n",
        "      output = model(input)\n",
        "\n",
        "      if isinstance(output, (tuple, list)):\n",
        "        output = output[0]\n",
        "      \n",
        "      loss = loss_fn(output, target)\n",
        "      acc1, _= accuracy(output, target, topk=(1, 2))\n",
        "\n",
        "      reduced_loss = loss.data_config\n",
        "\n",
        "      torch.cuda.synchronize()\n",
        "\n",
        "      losses_m.update(reduced_loss.item(), input.size(0))\n",
        "      accuracy_m.update(acc1.item(), output.size(0))\n",
        "\n",
        "      batch_time_m.update(time.time() - end)\n",
        "      end = time.time()\n",
        "  metrics = OrderedDict([('loss', losses_m.avg), ('accuracy', accuracy_m.avg)])\n",
        "\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "yQ-HaFtO4Xl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = num_epochs\n",
        "eval_metric = 'accuracy'\n",
        "best_metric = None\n",
        "best_epoch = None\n",
        "compare = operator.gt\n",
        "#学習結果CSVファイルやファインチューニング後のモデルデータの出力先\n",
        "output_dir = '/content/drive/MyDrive/VisionTransformer/output'"
      ],
      "metadata": {
        "id": "7nMWe_im76k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0, num_epochs):\n",
        "  train_metrics = train_one_epoch(\n",
        "      epoch, model, loader_train, optimizer, train_loss_fn, args, output_dir=output_dir\n",
        "  )\n",
        "\n",
        "  eval_metrics = validate(model, loader_eval, validate_loss_fn, args)\n",
        "\n",
        "  if output_dir is not None:\n",
        "    update_summary(\n",
        "        epoch,\n",
        "        train_metrics,\n",
        "        eval_metrics,\n",
        "        os.path.join(output_dir, 'summary.csv'),\n",
        "        write_header=best_metric is None,\n",
        "    )\n",
        "\n",
        "  metric = eval_metric[eval_metric]\n",
        "  if best_metric is None or compare(metric, best_metric):\n",
        "    best_metric = metric\n",
        "    best_epoch = epoch\n",
        "    torch.save(model.state_dict(), so.path.join(output_dir, 'best_model.pth'))\n",
        "  \n",
        "  print(epodh)\n",
        "  print(eval_metrics)\n",
        "  print('Best metric: {0} (epoch {1}'.format(best_metric, best_epoch))"
      ],
      "metadata": {
        "id": "uVJQj2rW81l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(\n",
        "    torch.load(\n",
        "        os.path.join(output_dir, 'best_model.pth'), map_location=torch.device('cuda')\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "mJTpLVW3BPZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "画像の変換とモデルのビルド"
      ],
      "metadata": {
        "id": "hOfytvkyDZ7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "image_size = data_config['input_size'][-1]\n",
        "loader = transformes.Compose([transforms.Resize(image_size), transforms.ToTensor()])\n",
        "def image_loder(image_name):\n",
        "  image = Image.open(image_name).convert('RGB')\n",
        "  image = loader(image)\n",
        "  image = Variable(image, requires_grad=True)\n",
        "  image = image.unsqueeze(0)\n",
        "  return image.cuda()\n",
        "m = nn.Softmax(dim=1)"
      ],
      "metadata": {
        "id": "8S3kydLWB3a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "空データ"
      ],
      "metadata": {
        "id": "r7PbuUqdFy22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clear_image_path = os.path.join(dataset_path, 'test/clear/12_3542_1635.png')\n",
        "predicted_clear_image = image_loader(clear_image_path)\n",
        "display(Image.open(clear_image_path))\n",
        "m(model(predicted_clear_image))"
      ],
      "metadata": {
        "id": "sZd-LPfSDjwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "雲データ"
      ],
      "metadata": {
        "id": "2fbCmcCgFvxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cloudy_image_path = os.path.join(dataset_path, 'test/clear/12_3542_1635.png')\n",
        "predicted_cloudy_image = image_loader(clear_image_path)\n",
        "display(Image.open(clear_image_path))\n",
        "m(model(predicted_cloudy_image))"
      ],
      "metadata": {
        "id": "jB7Je07CEn9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, loader, args):\n",
        "  batch_time_m = AverageMeter()\n",
        "  accuracy_m = AverageMeter()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  end = time.time()\n",
        "  with torch.no_grad():\n",
        "    for _, (input, target) in enumerate(loader):\n",
        "      input = input.cuda()\n",
        "      target = target.cuda()\n",
        "\n",
        "      outpput = model(input)\n",
        "\n",
        "      if isinstance(output, (tuple, list)):\n",
        "        output = output[0]\n",
        "      \n",
        "      acc1, _= accuracy(output, target, topk(1, 2))\n",
        "\n",
        "      torch.cuda.synchronize()\n",
        "\n",
        "      accuracy_m.update(time() - end)\n",
        "      end = time.time()\n",
        "  return {'accuracy': accuracy_m.avg}"
      ],
      "metadata": {
        "id": "tVQr_bnbF1Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, loader_test, args)"
      ],
      "metadata": {
        "id": "eaDNvgNzHhix"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}