{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxaPAPQZzUw-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from pytorch_transformers import BertForMaskedLM\n",
        "from pytorch_transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQbArYj1zUxE"
      },
      "outputs": [],
      "source": [
        "text = \"[CLS] | played baseball with my friends at school yesterday [SEP]\"\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")#←BEATベースアンケースドを使用\n",
        "words = tokenizer.tokenize(text)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_iNealnzUxF"
      },
      "source": [
        "tokenizer.tokenizeのところは注意rがついてるのと、ついてないの"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OXcEdPczUxH"
      },
      "source": [
        "ここから文章の一部をマスクする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY4-De0lzUxI"
      },
      "outputs": [],
      "source": [
        "msk_idx = 3#3番目0からカウント\n",
        "words[msk_idx] = \"[MASK]\"#単語を[MASK]に置き換える\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FKjQ3RLzUxI"
      },
      "source": [
        "ベースボールがMASKに置き換わる。\n",
        "次に単語を対応するインデックスに置き換える"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6emPVCezUxJ"
      },
      "outputs": [],
      "source": [
        "word_ids = tokenizer.convert_tokens_to_ids(words)#単語をインデックスに変換\n",
        "word_tensor = torch.tensor([word_ids])#テンソルに変換\n",
        "print(word_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qloFcT-AzUxK"
      },
      "source": [
        "それぞれ単語を表すIDに変換ができたのでBERTを使って予測をする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8gnXETIzUxL"
      },
      "outputs": [],
      "source": [
        "msk_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "msk_model.eval()#学習は行わないのでevalモードにする\n",
        "\n",
        "x = word_tensor\n",
        "y = msk_model(x)#予測\n",
        "result = y[0]\n",
        "print(result.size())#結果の形状\n",
        "\n",
        "_, max_ids = torch.topk(result[0][msk_idx],k=5)#最も大きい5つの値\n",
        "result_words = tokenizer.convert_ids_to_tokens(max_ids.tolist())#インデックスを単語に変換\n",
        "print(result_words)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU1ZNPofzUxM"
      },
      "source": [
        "GPU対応はできないのでなし。対応する場合はx = tensor.cuda()を記述する\n",
        "コードの流れは\n",
        "①word_tensor→xに入れる→msk_modelに投入→resultで取り出す→予測結果を上位５つ表示\n",
        "yのとこれで順伝番が行われてる\n",
        "_,は本来、一番大きな値が入るが今回は使わないのでアンダースコア\n",
        "②max_idsを(max_ids.tolist())でリストに変換→tokenizer.convert_ids_to_tokens()で単語に変換\n",
        "③print(result_words)で表示\n",
        "torch.sizeの中身解説\n",
        "[1]はバッチサイズ\n",
        "[11]は文章の中の単語数\n",
        "[30522]は単語数\n",
        "result_wordsの中身解説\n",
        "[MASK]した部分がbaseballなので本来なら、resultの1番目はbaseballになるはずだが\n",
        "出力は['football', 'basketball', 'golf', 'guitar', 'baseball']となった。\n",
        "5番目に入っているだけでもすごいことだが少し偏りを感じる。\n",
        "考察としてはモデル自体が海外より。海外の放課後の遊びは'football', 'basketball'が多いのかもしれない\n",
        "[MASK]する部分を変えると100%の精度が出るかもしれない"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.2  ('BT': venv)",
      "name": "pythonjvsc74a57bd063852291f8c4a68749fa18d2d71a3b435c3a94e3281432cd411943a4b6b3aaa0"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "metadata": {
      "interpreter": {
        "hash": "63852291f8c4a68749fa18d2d71a3b435c3a94e3281432cd411943a4b6b3aaa0"
      }
    },
    "orig_nbformat": 2,
    "colab": {
      "name": "maskedLM.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}